# What happens if file doesnâ€™t exist?
-->If the file cannot be opened, an OSError is raised.

# File mode characters and their meanings

| Character | Meaning                                                      |
|-----------|--------------------------------------------------------------|
| 'r'       | open for reading (default)                                   |
| 'w'       | open for writing, truncating the file first                  |
| 'x'       | open for exclusive creation, failing if the file already exists |
| 'a'       | open for writing, appending to the end of file if it exists  |
| 'b'       | binary mode                                                  |
| 't'       | text mode (default)                                          |
| '+'       | open for updating (reading and writing)                      |


# The default mode is 'r' (open for reading text, a synonym of 'rt'). Modes 'w+' and 'w+b' open and truncate the file. Modes 'r+' and 'r+b' open the file with no truncation.

# What happens if data is malformed
-->If the data is malformed, different exceptions may be raised depending on the operation being performed. For example, a ValueError may occur when trying to convert a string to an integer if the string does not represent a valid integer.

# What My ETL pipeline does
-->The ETL pipeline extracts data from source files, transforms the data by cleaning and filtering it, and then loads the processed data into a target file or database.

# Why did I separate logic into utils.py
-->Separating logic into utils.py helps to keep the code organized and modular. It allows for easier maintenance, testing, and reuse of functions across different parts of the ETL pipeline.

# How would I scale this beyond files
-->To scale the ETL pipeline beyond files, I would consider integrating with databases, data lakes, or cloud storage solutions. I could use libraries like SQLAlchemy for database interactions or frameworks like Apache Airflow for orchestrating complex workflows. Additionally, I would implement parallel processing or distributed computing techniques to handle larger datasets efficiently.